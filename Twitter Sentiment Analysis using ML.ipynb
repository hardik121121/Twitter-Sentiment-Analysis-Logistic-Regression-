{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis - Analyzes tweets to determine wether they express positive or negative sentiments\n",
    "\n",
    "Step1 : Collect tweet data\n",
    "Step2 : Preprocess - Convert textual data to numerical\n",
    "Step3 : Train-Test Split\n",
    "Step4 : Using Logistic Regress because it is a Classification model\n",
    "Step5 : After training the model if we give it a tweet it will analyze its sentiment as Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\asus\\onedrive\\desktop\\twitter sentiment analysis\\myenv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Collecting certifi>=2023.7.22 (from kaggle)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\asus\\onedrive\\desktop\\twitter sentiment analysis\\myenv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting requests (from kaggle)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting urllib3 (from kaggle)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kaggle)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kaggle)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\onedrive\\desktop\\twitter sentiment analysis\\myenv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (pyproject.toml): started\n",
      "  Building wheel for kaggle (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105797 sha256=63b03e13846b2921e671b72c8819a024ff26b1a350237faecf0b935015eed22d\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\46\\d2\\26\\84d0a1acdb9c6baccf7d28cf06962ec80529fe1ad938489983\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "Successfully installed bleach-6.2.0 certifi-2024.12.14 charset-normalizer-3.4.1 idna-3.10 kaggle-1.6.17 python-slugify-8.0.4 requests-2.32.3 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.3.0 webencodings-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Load datset from kaggle via api\n",
    "# installing kaggle library\n",
    "\n",
    "! pip install kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploaded kaggle.json file which contains my api details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration of kaggle.json completed.\n"
     ]
    }
   ],
   "source": [
    "# configuring path of kaggle.json file\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create the .kaggle directory in the user's home directory\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "\n",
    "# Copy kaggle.json to the .kaggle directory\n",
    "shutil.copy(\"kaggle.json\", os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
    "\n",
    "# Set permissions for kaggle.json\n",
    "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
    "\n",
    "print(\"Configuration of kaggle.json completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Twitter Sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
      "License(s): other\n",
      "Downloading sentiment140.zip to c:\\Users\\Asus\\OneDrive\\Desktop\\Twitter Sentiment Analysis\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/80.9M [00:00<?, ?B/s]\n",
      "  1%|          | 1.00M/80.9M [00:03<04:01, 347kB/s]\n",
      "  2%|▏         | 2.00M/80.9M [00:06<04:30, 306kB/s]\n",
      "  4%|▎         | 3.00M/80.9M [00:09<03:47, 359kB/s]\n",
      "  5%|▍         | 4.00M/80.9M [00:11<03:34, 376kB/s]\n",
      "  6%|▌         | 5.00M/80.9M [00:21<06:34, 202kB/s]\n",
      "  7%|▋         | 6.00M/80.9M [00:23<05:25, 241kB/s]\n",
      "  9%|▊         | 7.00M/80.9M [00:27<05:17, 244kB/s]\n",
      " 10%|▉         | 8.00M/80.9M [00:32<05:29, 232kB/s]\n",
      " 11%|█         | 9.00M/80.9M [00:37<05:24, 233kB/s]\n",
      " 12%|█▏        | 10.0M/80.9M [00:44<06:21, 195kB/s]\n",
      " 14%|█▎        | 11.0M/80.9M [00:50<06:31, 187kB/s]\n",
      " 15%|█▍        | 12.0M/80.9M [00:56<06:31, 185kB/s]\n",
      " 16%|█▌        | 13.0M/80.9M [01:04<07:15, 164kB/s]\n",
      " 17%|█▋        | 14.0M/80.9M [01:08<06:15, 187kB/s]\n",
      " 19%|█▊        | 15.0M/80.9M [01:14<06:15, 184kB/s]\n",
      " 20%|█▉        | 16.0M/80.9M [01:17<05:21, 212kB/s]\n",
      " 21%|██        | 17.0M/80.9M [01:21<04:52, 229kB/s]\n",
      " 22%|██▏       | 18.0M/80.9M [01:24<04:16, 258kB/s]\n",
      " 23%|██▎       | 19.0M/80.9M [01:28<04:21, 248kB/s]\n",
      " 25%|██▍       | 20.0M/80.9M [01:31<03:54, 272kB/s]\n",
      " 26%|██▌       | 21.0M/80.9M [01:35<03:46, 278kB/s]\n",
      " 27%|██▋       | 22.0M/80.9M [01:39<03:53, 265kB/s]\n",
      " 28%|██▊       | 23.0M/80.9M [01:45<04:16, 236kB/s]\n",
      " 30%|██▉       | 24.0M/80.9M [01:54<05:29, 181kB/s]\n",
      " 31%|███       | 25.0M/80.9M [01:59<05:07, 190kB/s]\n",
      " 32%|███▏      | 26.0M/80.9M [02:02<04:21, 220kB/s]\n",
      " 33%|███▎      | 27.0M/80.9M [02:06<04:16, 220kB/s]\n",
      " 35%|███▍      | 28.0M/80.9M [02:12<04:21, 212kB/s]\n",
      " 36%|███▌      | 29.0M/80.9M [02:16<04:10, 217kB/s]\n",
      " 37%|███▋      | 30.0M/80.9M [02:21<03:58, 224kB/s]\n",
      " 38%|███▊      | 31.0M/80.9M [02:29<04:42, 185kB/s]\n",
      " 40%|███▉      | 32.0M/80.9M [02:35<04:43, 181kB/s]\n",
      " 41%|████      | 33.0M/80.9M [02:40<04:29, 186kB/s]\n",
      " 42%|████▏     | 34.0M/80.9M [02:46<04:24, 186kB/s]\n",
      " 43%|████▎     | 35.0M/80.9M [02:50<03:55, 205kB/s]\n",
      " 44%|████▍     | 36.0M/80.9M [02:53<03:20, 235kB/s]\n",
      " 46%|████▌     | 37.0M/80.9M [02:56<02:57, 260kB/s]\n",
      " 47%|████▋     | 38.0M/80.9M [02:59<02:40, 280kB/s]\n",
      " 48%|████▊     | 39.0M/80.9M [03:02<02:32, 287kB/s]\n",
      " 49%|████▉     | 40.0M/80.9M [03:05<02:14, 318kB/s]\n",
      " 51%|█████     | 41.0M/80.9M [03:08<02:18, 302kB/s]\n",
      " 52%|█████▏    | 42.0M/80.9M [03:12<02:19, 293kB/s]\n",
      " 53%|█████▎    | 43.0M/80.9M [03:16<02:21, 281kB/s]\n",
      " 54%|█████▍    | 44.0M/80.9M [03:20<02:15, 287kB/s]\n",
      " 56%|█████▌    | 45.0M/80.9M [03:25<02:22, 265kB/s]\n",
      " 57%|█████▋    | 46.0M/80.9M [03:29<02:19, 262kB/s]\n",
      " 58%|█████▊    | 47.0M/80.9M [03:34<02:27, 241kB/s]\n",
      " 59%|█████▉    | 48.0M/80.9M [03:39<02:27, 234kB/s]\n",
      " 61%|██████    | 49.0M/80.9M [03:42<02:13, 250kB/s]\n",
      " 62%|██████▏   | 50.0M/80.9M [03:47<02:12, 244kB/s]\n",
      " 63%|██████▎   | 51.0M/80.9M [03:50<02:04, 252kB/s]\n",
      " 64%|██████▍   | 52.0M/80.9M [03:53<01:47, 283kB/s]\n",
      " 65%|██████▌   | 53.0M/80.9M [03:56<01:39, 295kB/s]\n",
      " 67%|██████▋   | 54.0M/80.9M [04:00<01:34, 298kB/s]\n",
      " 68%|██████▊   | 55.0M/80.9M [04:05<01:41, 267kB/s]\n",
      " 69%|██████▉   | 56.0M/80.9M [04:08<01:37, 269kB/s]\n",
      " 70%|███████   | 57.0M/80.9M [04:13<01:39, 253kB/s]\n",
      " 72%|███████▏  | 58.0M/80.9M [04:16<01:27, 276kB/s]\n",
      " 73%|███████▎  | 59.0M/80.9M [04:20<01:24, 273kB/s]\n",
      " 74%|███████▍  | 60.0M/80.9M [04:23<01:14, 296kB/s]\n",
      " 75%|███████▌  | 61.0M/80.9M [04:27<01:13, 283kB/s]\n",
      " 77%|███████▋  | 62.0M/80.9M [04:31<01:11, 277kB/s]\n",
      " 78%|███████▊  | 63.0M/80.9M [04:35<01:07, 276kB/s]\n",
      " 79%|███████▉  | 64.0M/80.9M [04:38<01:03, 280kB/s]\n",
      " 80%|████████  | 65.0M/80.9M [04:43<01:04, 261kB/s]\n",
      " 82%|████████▏ | 66.0M/80.9M [04:47<01:00, 257kB/s]\n",
      " 83%|████████▎ | 67.0M/80.9M [04:52<00:58, 250kB/s]\n",
      " 84%|████████▍ | 68.0M/80.9M [04:56<00:54, 247kB/s]\n",
      " 85%|████████▌ | 69.0M/80.9M [05:01<00:52, 239kB/s]\n",
      " 87%|████████▋ | 70.0M/80.9M [05:05<00:47, 243kB/s]\n",
      " 88%|████████▊ | 71.0M/80.9M [05:09<00:41, 251kB/s]\n",
      " 89%|████████▉ | 72.0M/80.9M [05:12<00:34, 273kB/s]\n",
      " 90%|█████████ | 73.0M/80.9M [05:16<00:30, 274kB/s]\n",
      " 91%|█████████▏| 74.0M/80.9M [05:20<00:26, 272kB/s]\n",
      " 93%|█████████▎| 75.0M/80.9M [05:25<00:24, 250kB/s]\n",
      " 94%|█████████▍| 76.0M/80.9M [05:30<00:21, 235kB/s]\n",
      " 95%|█████████▌| 77.0M/80.9M [05:34<00:17, 233kB/s]\n",
      " 96%|█████████▋| 78.0M/80.9M [05:40<00:14, 216kB/s]\n",
      " 98%|█████████▊| 79.0M/80.9M [05:44<00:08, 227kB/s]\n",
      " 99%|█████████▉| 80.0M/80.9M [05:49<00:04, 220kB/s]\n",
      "100%|██████████| 80.9M/80.9M [05:53<00:00, 226kB/s]\n",
      "100%|██████████| 80.9M/80.9M [05:53<00:00, 240kB/s]\n"
     ]
    }
   ],
   "source": [
    "# API to fetch the dataset from kaggle\n",
    "\n",
    "!kaggle datasets download -d kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is extracted\n"
     ]
    }
   ],
   "source": [
    "# Extracting the compressed dataset\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "dataset = 'sentiment140.zip'\n",
    "\n",
    "with ZipFile(dataset , 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('The dataset is extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Printing the stopwords in English\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from csv file to pandas dataframe\n",
    "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows and columns\n",
    "\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "0        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599994  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "         _TheSpecialOne_  \\\n",
       "0          scotthamilton   \n",
       "1               mattycus   \n",
       "2                ElleCTF   \n",
       "3                 Karoli   \n",
       "4               joy_wolf   \n",
       "...                  ...   \n",
       "1599994  AmandaMarie1028   \n",
       "1599995      TheWDBoards   \n",
       "1599996           bpbabe   \n",
       "1599997     tinydiamondz   \n",
       "1599998   RyanTrevMorris   \n",
       "\n",
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0        is upset that he can't update his Facebook by ...                                                                   \n",
       "1        @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2          my whole body feels itchy and like its on fire                                                                    \n",
       "3        @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                            @Kwesidei not the whole crew                                                                    \n",
       "...                                                    ...                                                                   \n",
       "1599994  Just woke up. Having no school is the best fee...                                                                   \n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...                                                                   \n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...                                                                   \n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...                                                                   \n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...                                                                   \n",
       "\n",
       "[1599999 rows x 6 columns]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing first 5 rows of the dataframe\n",
    "twitter_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the columns and reading the dataset again\n",
    "\n",
    "column_names = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv',names= column_names, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows and columns after including the column names\n",
    "\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          target          id                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing first 5 rows of the dataframe\n",
    "twitter_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Missing Values in the dataset\n",
    "\n",
    "twitter_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of target Column - how many positive tweets are there and how many negative tweets are there\n",
    "twitter_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the distribution of data is equal for both positive and negative sentiments it is fine otherwise we would have done upsampling and downsampling to equalize the dataset for ml model to perform accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target '4' to '1'\n",
    "\n",
    "twitter_data.replace({'target' : {4:1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of target Column after converting 4 to 1 - how many positive tweets are there and how many negative tweets are there\n",
    "twitter_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 --> Negative Tweet \n",
    "\n",
    "1 --> Positive Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming - Reducing word to root word - For reducing dimensions and complexities\n",
    "\n",
    "#Losding the porterstemmer module to the variable\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the template for the stemming function\n",
    "def stemming(content):\n",
    "     stemmed_content = re.sub('{^a-zA-Z}',' ', content)\n",
    "     stemmed_content = stemmed_content.lower()\n",
    "     stemmed_content = stemmed_content.split()\n",
    "     stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "     stemmed_content = ' '.join(stemmed_content)\n",
    "\n",
    "     return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying stemming to my data\n",
    "\n",
    "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)\n",
    "\n",
    "# takes long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          target          id                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       1  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       1  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       1  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       1  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       1  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \\\n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "...                  ...                                                ...   \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...   \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                           stemmed_content  \n",
       "0        @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1        upset can't updat facebook text it... might cr...  \n",
       "2        @kenichan dive mani time ball. manag save 50% ...  \n",
       "3                          whole bodi feel itchi like fire  \n",
       "4        @nationwideclass no, behav all. i'm mad. here?...  \n",
       "...                                                    ...  \n",
       "1599995                     woke up. school best feel ever  \n",
       "1599996  thewdb.com - cool hear old walt interviews! â...  \n",
       "1599997                    readi mojo makeover? ask detail  \n",
       "1599998  happi 38th birthday boo alll time!!! tupac ama...  \n",
       "1599999  happi #charitytuesday @thenspcc @sparkschar @s...  \n",
       "\n",
       "[1600000 rows x 7 columns]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying dataset after stemming\n",
    "twitter_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
      "1          upset can't updat facebook text it... might cr...\n",
      "2          @kenichan dive mani time ball. manag save 50% ...\n",
      "3                            whole bodi feel itchi like fire\n",
      "4          @nationwideclass no, behav all. i'm mad. here?...\n",
      "                                 ...                        \n",
      "1599995                       woke up. school best feel ever\n",
      "1599996    thewdb.com - cool hear old walt interviews! â...\n",
      "1599997                      readi mojo makeover? ask detail\n",
      "1599998    happi 38th birthday boo alll time!!! tupac ama...\n",
      "1599999    happi #charitytuesday @thenspcc @sparkschar @s...\n",
      "Name: stemmed_content, Length: 1600000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# stemmed_content(16 lakh tweets) and the target variable are required for training my model\n",
    "\n",
    "print(twitter_data['stemmed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the data - tweet(x) and label-target(y)\n",
    "\n",
    "X = twitter_data['stemmed_content'].values\n",
    "Y = twitter_data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@switchfoot http://twitpic.com/2y1zl - awww, that' bummer. shoulda got david carr third day it. ;d\"\n",
      " \"upset can't updat facebook text it... might cri result school today also. blah!\"\n",
      " '@kenichan dive mani time ball. manag save 50% rest go bound' ...\n",
      " 'readi mojo makeover? ask detail'\n",
      " 'happi 38th birthday boo alll time!!! tupac amaru shakur'\n",
      " 'happi #charitytuesday @thenspcc @sparkschar @speakinguph4h']\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data to training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000,) (1280000,) (320000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Going to ml model we need to convert textual data to numeric by feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the textual data to numerical data\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test) \n",
    "\n",
    "# words will get importance on the basis of repitition and corresponds to positive or negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 10033748 stored elements and shape (1280000, 578847)>\n",
      "  Coords\tValues\n",
      "  (0, 548734)\t0.272460245511403\n",
      "  (0, 453116)\t0.35795997954657904\n",
      "  (0, 254267)\t0.5248773503338933\n",
      "  (0, 166830)\t0.37842601975344053\n",
      "  (0, 311959)\t0.4213989894780769\n",
      "  (0, 555967)\t0.448720931098355\n",
      "  (1, 226262)\t0.9067376665899747\n",
      "  (1, 247278)\t0.4216951552804088\n",
      "  (2, 166830)\t0.46135196432581543\n",
      "  (2, 184426)\t0.19030000160550456\n",
      "  (2, 514638)\t0.18602125106063966\n",
      "  (2, 190522)\t0.2919883395488319\n",
      "  (2, 513655)\t0.32017162311057684\n",
      "  (2, 545128)\t0.32796751926832923\n",
      "  (2, 129252)\t0.3117944515681845\n",
      "  (2, 556376)\t0.3361458059516176\n",
      "  (2, 349418)\t0.24085594662276874\n",
      "  (2, 516778)\t0.15260594669966598\n",
      "  (2, 245846)\t0.16108271281506445\n",
      "  (2, 214788)\t0.1869628699148727\n",
      "  (2, 193769)\t0.2018446658815102\n",
      "  (2, 375364)\t0.16689112338294135\n",
      "  (3, 513655)\t0.2889371658693274\n",
      "  (3, 223959)\t0.4482843351756085\n",
      "  (3, 215997)\t0.27659430167424054\n",
      "  :\t:\n",
      "  (1279996, 494789)\t0.21762890963383247\n",
      "  (1279996, 474688)\t0.35639996447938693\n",
      "  (1279996, 315574)\t0.5365422013140488\n",
      "  (1279996, 315576)\t0.5521217554769912\n",
      "  (1279997, 44706)\t0.48636648837048746\n",
      "  (1279997, 356925)\t0.4370667160334468\n",
      "  (1279997, 170751)\t0.756584644785961\n",
      "  (1279998, 520651)\t0.269316141394904\n",
      "  (1279998, 148756)\t0.2118527438431575\n",
      "  (1279998, 236205)\t0.25653005663760886\n",
      "  (1279998, 184747)\t0.3236576174473998\n",
      "  (1279998, 108107)\t0.25117292480034903\n",
      "  (1279998, 547278)\t0.2733774862738663\n",
      "  (1279998, 217739)\t0.2714152969928637\n",
      "  (1279998, 227873)\t0.33189749575982486\n",
      "  (1279998, 221128)\t0.31225888314408684\n",
      "  (1279998, 359534)\t0.3709990646978321\n",
      "  (1279998, 489069)\t0.3939975789563404\n",
      "  (1279999, 320388)\t0.170398690822026\n",
      "  (1279999, 74997)\t0.21507960919293484\n",
      "  (1279999, 547406)\t0.2743907439808635\n",
      "  (1279999, 545182)\t0.3255220579273754\n",
      "  (1279999, 233246)\t0.4391237583174431\n",
      "  (1279999, 197306)\t0.5759202424536238\n",
      "  (1279999, 151607)\t0.4679063544227965\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 2411495 stored elements and shape (320000, 578847)>\n",
      "  Coords\tValues\n",
      "  (0, 55622)\t0.17041370659097008\n",
      "  (0, 74691)\t0.1610538837848407\n",
      "  (0, 117476)\t0.26691751430897404\n",
      "  (0, 163021)\t0.37372158998727745\n",
      "  (0, 193829)\t0.2532904390317208\n",
      "  (0, 200572)\t0.23596147172673212\n",
      "  (0, 238369)\t0.2869441563378548\n",
      "  (0, 354509)\t0.449467530296984\n",
      "  (0, 364065)\t0.17667781375470604\n",
      "  (0, 492691)\t0.21841828884993894\n",
      "  (0, 505258)\t0.3459496612358391\n",
      "  (0, 516778)\t0.31514526424889533\n",
      "  (0, 530649)\t0.17887663933344994\n",
      "  (1, 45607)\t0.3039118621705182\n",
      "  (1, 55622)\t0.20816041520057577\n",
      "  (1, 208893)\t0.5712382041014992\n",
      "  (1, 291622)\t0.4070550884371154\n",
      "  (1, 337825)\t0.2840187026690571\n",
      "  (1, 445343)\t0.48174286114843634\n",
      "  (1, 466635)\t0.24404319903374125\n",
      "  (2, 64354)\t0.3536656204135894\n",
      "  (2, 78469)\t0.3786845038674409\n",
      "  (2, 143688)\t0.3624696061947235\n",
      "  (2, 252255)\t0.5874470296410402\n",
      "  (2, 337915)\t0.2587039123196698\n",
      "  :\t:\n",
      "  (319995, 220218)\t0.24721323590915964\n",
      "  (319995, 286854)\t0.23929241469707901\n",
      "  (319995, 309466)\t0.22958307832752411\n",
      "  (319995, 316463)\t0.2041503310854718\n",
      "  (319995, 384821)\t0.40236048960872395\n",
      "  (319995, 407164)\t0.2582052217116053\n",
      "  (319995, 417479)\t0.3357981149453034\n",
      "  (319995, 526794)\t0.39930162664337965\n",
      "  (319995, 530649)\t0.20324009692596\n",
      "  (319995, 557995)\t0.28622199305835194\n",
      "  (319996, 503607)\t0.9031149256968758\n",
      "  (319996, 551017)\t0.42939891823748993\n",
      "  (319997, 14749)\t0.5224405165357664\n",
      "  (319997, 154665)\t0.41735152291209354\n",
      "  (319997, 236141)\t0.3336334511815061\n",
      "  (319997, 343074)\t0.31311405056425523\n",
      "  (319997, 375306)\t0.40064371018869743\n",
      "  (319997, 447602)\t0.2706555344060331\n",
      "  (319997, 525586)\t0.24398324651652456\n",
      "  (319997, 557807)\t0.22410778477696092\n",
      "  (319998, 191361)\t0.6947067518869656\n",
      "  (319998, 551063)\t0.7192930757922404\n",
      "  (319999, 494360)\t0.9093329003875843\n",
      "  (319999, 507241)\t0.2838966534256726\n",
      "  (319999, 571346)\t0.3041650315970051\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the ML Model - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Model Evaluation - We use Accuracy Score\n",
    "\n",
    "# Acuracy Score on the training_data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the training data :  0.8119328125\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score on the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acuracy Score on the testing_data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the testing data :  0.781615625\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score on the testing data : ', testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy = testing_data_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'trained_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the saved model for future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Positive Tweet\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[200]\n",
    "Y_new = Y_test[200]\n",
    "\n",
    "prediction = loaded_model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "    print('Negative Tweet')\n",
    "else:\n",
    "    print('Positive Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the vectorizer\n",
    "\n",
    "# Save the vectorizer after fitting on training data\n",
    "pickle.dump(vectorizer, open('vectorizer.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
